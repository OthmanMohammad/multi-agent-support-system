"""
Link Checker Agent - TASK-2107

Verifies all links in responses are valid and return HTTP 200.
Checks documentation links, API references, and external resources.
Uses Claude Haiku for efficient link validation.
"""

from typing import Dict, Any, List, Optional
from datetime import datetime, UTC
import re

from src.workflow.state import AgentState
from src.agents.base import BaseAgent, AgentConfig, AgentType, AgentCapability
from src.utils.logging.setup import get_logger
from src.services.infrastructure.agent_registry import AgentRegistry


@AgentRegistry.register("link_checker", tier="operational", category="qa")
class LinkCheckerAgent(BaseAgent):
    """
    Link Checker Agent.

    Validates all links in responses:
    - Extracts URLs from response text
    - Verifies HTTP status codes (expects 200)
    - Checks for broken links (404, 500, etc.)
    - Validates link relevance and context
    - Detects redirects and warns about moved content
    - Checks internal vs external links
    - Validates documentation links against knowledge base

    Uses Claude Haiku for efficient link checking.
    """

    # HTTP status codes and their severity
    STATUS_SEVERITY = {
        200: "success",      # OK
        301: "warning",      # Moved Permanently
        302: "warning",      # Found (temporary redirect)
        400: "high",         # Bad Request
        401: "high",         # Unauthorized
        403: "high",         # Forbidden
        404: "critical",     # Not Found
        500: "critical",     # Internal Server Error
        503: "high"          # Service Unavailable
    }

    # Link categories
    LINK_CATEGORIES = {
        "documentation": ["docs.", "/docs/", "documentation"],
        "api_reference": ["api.", "/api/", "reference"],
        "github": ["github.com"],
        "external": ["http://", "https://"],
        "internal": ["/"]
    }

    def __init__(self):
        config = AgentConfig(
            name="link_checker",
            type=AgentType.ANALYZER,
            model="claude-3-haiku-20240307",
            temperature=0.1,
            max_tokens=1500,
            capabilities=[],
            tier="operational"
        )
        super().__init__(config)
        self.logger = get_logger(__name__)

    async def process(self, state: AgentState) -> AgentState:
        """
        Check all links in response.

        Args:
            state: Current agent state with response to check

        Returns:
            Updated state with link validation results
        """
        self.logger.info("link_checking_started")

        state = self.update_state(state)

        # Extract parameters
        response_text = state.get("entities", {}).get("response_text", state.get("agent_response", ""))
        check_external = state.get("entities", {}).get("check_external", True)

        self.logger.debug(
            "link_checking_details",
            response_length=len(response_text),
            check_external=check_external
        )

        # Extract links
        links = self._extract_links(response_text)

        if not links:
            # No links to validate
            state["agent_response"] = "No links found in response"
            state["link_check_passed"] = True
            state["links_found"] = 0
            state["link_score"] = 100.0
            state["response_confidence"] = 0.99
            state["status"] = "resolved"
            state["next_agent"] = None
            return state

        # Validate each link
        validation_results = []
        for link in links:
            result = self._validate_link(link, check_external)
            validation_results.append(result)

        # Identify issues
        issues = self._identify_link_issues(validation_results)

        # Generate recommendations
        recommendations = self._generate_recommendations(validation_results, issues)

        # Calculate link score
        link_score = self._calculate_link_score(validation_results)

        # Determine pass/fail
        passed = self._determine_pass_fail(issues)

        # Format response
        response = self._format_link_report(
            links,
            validation_results,
            issues,
            recommendations,
            link_score,
            passed
        )

        state["agent_response"] = response
        state["link_check_passed"] = passed
        state["link_score"] = link_score
        state["links_found"] = len(links)
        state["validation_results"] = validation_results
        state["link_issues"] = issues
        state["recommendations"] = recommendations
        state["response_confidence"] = 0.93
        state["status"] = "resolved"
        state["next_agent"] = None

        self.logger.info(
            "link_checking_completed",
            links_checked=len(links),
            issues_found=len(issues),
            link_score=link_score,
            passed=passed
        )

        return state

    def _extract_links(self, response_text: str) -> List[Dict[str, Any]]:
        """
        Extract all links from response.

        Args:
            response_text: Response text

        Returns:
            List of links with metadata
        """
        links = []

        # Pattern for URLs
        url_pattern = r'https?://[^\s<>"{}|\\^`\[\]]+'
        matches = re.finditer(url_pattern, response_text)

        for i, match in enumerate(matches):
            url = match.group(0).rstrip(".,!?)")  # Remove trailing punctuation
            category = self._categorize_link(url)

            links.append({
                "link_id": f"link_{i}",
                "url": url,
                "category": category,
                "position": match.start(),
                "context": self._extract_link_context(response_text, match.start())
            })

        # Also check for markdown links
        markdown_pattern = r'\[([^\]]+)\]\(([^)]+)\)'
        md_matches = re.finditer(markdown_pattern, response_text)

        for i, match in enumerate(md_matches):
            link_text = match.group(1)
            url = match.group(2)
            category = self._categorize_link(url)

            # Only add if not already in list
            if not any(link["url"] == url for link in links):
                links.append({
                    "link_id": f"md_link_{i}",
                    "url": url,
                    "link_text": link_text,
                    "category": category,
                    "position": match.start(),
                    "context": self._extract_link_context(response_text, match.start())
                })

        return links

    def _categorize_link(self, url: str) -> str:
        """Categorize link by type."""
        url_lower = url.lower()

        for category, patterns in self.LINK_CATEGORIES.items():
            if any(pattern in url_lower for pattern in patterns):
                return category

        return "other"

    def _extract_link_context(self, text: str, position: int) -> str:
        """Extract surrounding context for a link."""
        start = max(0, position - 50)
        end = min(len(text), position + 100)
        context = text[start:end].strip()

        if start > 0:
            context = "..." + context
        if end < len(text):
            context = context + "..."

        return context

    def _validate_link(self, link: Dict[str, Any], check_external: bool) -> Dict[str, Any]:
        """
        Validate a single link.

        Args:
            link: Link to validate
            check_external: Whether to check external links

        Returns:
            Validation result
        """
        url = link["url"]
        issues = []

        # Simulate HTTP check (in production, would make actual HTTP request)
        # For now, use heuristics

        # Check for common broken link patterns
        if "localhost" in url:
            issues.append({
                "type": "localhost_link",
                "severity": "critical",
                "message": "Link points to localhost (won't work for customers)"
            })

        if "example.com" in url or "example.org" in url:
            issues.append({
                "type": "example_link",
                "severity": "high",
                "message": "Link contains example domain - replace with actual URL"
            })

        # Check for incomplete URLs
        if url.startswith("http:") and link["category"] != "github":
            issues.append({
                "type": "insecure_http",
                "severity": "medium",
                "message": "Using HTTP instead of HTTPS (security concern)"
            })

        # Check for URL structure issues
        if " " in url:
            issues.append({
                "type": "malformed_url",
                "severity": "critical",
                "message": "URL contains spaces (malformed)"
            })

        # Mock HTTP status (in production, would actually check)
        # Assume most links are valid for mock
        http_status = 200
        if any(issue["severity"] == "critical" for issue in issues):
            http_status = 404

        # Determine overall status
        if issues:
            status = "failed"
        elif http_status != 200:
            status = "warning"
        else:
            status = "valid"

        return {
            "link_id": link["link_id"],
            "url": url,
            "category": link["category"],
            "http_status": http_status,
            "status": status,
            "issues": issues,
            "checked_at": datetime.now(UTC).isoformat()
        }

    def _identify_link_issues(self, validation_results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Identify all link issues."""
        all_issues = []

        for result in validation_results:
            for issue in result["issues"]:
                all_issues.append({
                    **issue,
                    "link_id": result["link_id"],
                    "url": result["url"],
                    "category": result["category"]
                })

            # Add HTTP status issues
            if result["http_status"] != 200:
                severity = self.STATUS_SEVERITY.get(result["http_status"], "medium")
                all_issues.append({
                    "type": "http_error",
                    "severity": severity,
                    "message": f"HTTP {result['http_status']} error",
                    "link_id": result["link_id"],
                    "url": result["url"],
                    "category": result["category"]
                })

        return all_issues

    def _generate_recommendations(
        self,
        validation_results: List[Dict[str, Any]],
        issues: List[Dict[str, Any]]
    ) -> List[str]:
        """Generate link validation recommendations."""
        recommendations = []

        if not issues:
            recommendations.append("All links are valid and accessible")
            return recommendations

        # Count by severity
        critical = [i for i in issues if i["severity"] == "critical"]
        high = [i for i in issues if i["severity"] == "high"]
        medium = [i for i in issues if i["severity"] == "medium"]

        if critical:
            recommendations.append(
                f"CRITICAL: Fix {len(critical)} broken or invalid links before sending"
            )

        if high:
            recommendations.append(
                f"HIGH PRIORITY: Address {len(high)} link issues"
            )

        # Specific recommendations
        issue_types = {}
        for issue in issues:
            issue_type = issue["type"]
            issue_types[issue_type] = issue_types.get(issue_type, 0) + 1

        if "localhost_link" in issue_types:
            recommendations.append(
                "Replace localhost links with public URLs or remove them"
            )

        if "example_link" in issue_types:
            recommendations.append(
                "Replace example domain placeholders with actual documentation URLs"
            )

        if "insecure_http" in issue_types:
            recommendations.append(
                "Update HTTP links to HTTPS for security"
            )

        if "http_error" in issue_types:
            recommendations.append(
                "Verify broken links and update to working URLs"
            )

        return recommendations

    def _calculate_link_score(self, validation_results: List[Dict[str, Any]]) -> float:
        """Calculate link quality score (0-100)."""
        if not validation_results:
            return 100.0

        valid_count = sum(1 for r in validation_results if r["status"] == "valid")
        total_count = len(validation_results)

        # Base score on percentage of valid links
        base_score = (valid_count / total_count) * 100

        # Deduct for issues
        total_deduction = 0
        for result in validation_results:
            for issue in result["issues"]:
                severity = issue["severity"]
                deductions = {"critical": 15, "high": 8, "medium": 4, "low": 1}
                total_deduction += deductions.get(severity, 0)

        final_score = max(0, base_score - total_deduction)

        return round(final_score, 1)

    def _determine_pass_fail(self, issues: List[Dict[str, Any]]) -> bool:
        """Determine if link check passes."""
        # Fail if any critical issues
        critical_issues = [i for i in issues if i["severity"] == "critical"]
        return len(critical_issues) == 0

    def _format_link_report(
        self,
        links: List[Dict[str, Any]],
        validation_results: List[Dict[str, Any]],
        issues: List[Dict[str, Any]],
        recommendations: List[str],
        link_score: float,
        passed: bool
    ) -> str:
        """Format link validation report."""
        status_icon = "âœ…" if passed else "âŒ"

        report = f"""**Link Validation Report**

**Status:** {status_icon} {"PASSED" if passed else "FAILED"}
**Link Score:** {link_score}/100
**Links Found:** {len(links)}
**Issues Detected:** {len(issues)}

**Link Categories:**
"""

        # Count by category
        categories = {}
        for link in links:
            cat = link["category"]
            categories[cat] = categories.get(cat, 0) + 1

        for category, count in categories.items():
            report += f"- {category.replace('_', ' ').title()}: {count}\n"

        # Validation results
        report += f"\n**Link Validation:**\n"
        for result in validation_results[:10]:  # Top 10 links
            status = "âœ“" if result["status"] == "valid" else "âœ—"
            report += f"{status} {result['url']} - HTTP {result['http_status']}\n"

        if len(validation_results) > 10:
            report += f"... and {len(validation_results) - 10} more links\n"

        # Issues
        if issues:
            report += f"\n**Issues Detected:**\n"
            for issue in issues[:5]:
                icon = "ðŸ”´" if issue["severity"] == "critical" else "âš ï¸" if issue["severity"] == "high" else "â„¹ï¸"
                report += f"{icon} [{issue['severity'].upper()}] {issue['message']}\n"
                report += f"   URL: {issue['url']}\n"

            if len(issues) > 5:
                report += f"... and {len(issues) - 5} more issues\n"

        # Recommendations
        if recommendations:
            report += f"\n**Recommendations:**\n"
            for rec in recommendations:
                report += f"- {rec}\n"

        report += f"\n*Link check completed at {datetime.now(UTC).isoformat()}*"

        return report
